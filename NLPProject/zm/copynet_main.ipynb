{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"copynet_main.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fcefa0a9ebb049f5823a4946e0fdf71a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6c613c9956694a4fb527940584ddf838","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7557ea80e8d74e2588ab92e1935822c4","IPY_MODEL_98079e483d2046df803a9059aeb5339c"]}},"6c613c9956694a4fb527940584ddf838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7557ea80e8d74e2588ab92e1935822c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_43d5ec8cf69d49d29438aad73fd32f20","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"danger","max":519,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29d44bfc70c74dde8c673acb141f6d92"}},"98079e483d2046df803a9059aeb5339c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_19a9a8222d7b4b81a59a7aa124baae25","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/519 [00:01&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dbaabe5e35c9494ab78f205370949d1f"}},"43d5ec8cf69d49d29438aad73fd32f20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"29d44bfc70c74dde8c673acb141f6d92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19a9a8222d7b4b81a59a7aa124baae25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dbaabe5e35c9494ab78f205370949d1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Y7_Icc0tqz3V"},"source":["# TO DO TO RUN\n","1. You need to add the `.item()` for `words.append(idx_to_tok[idx.item()])` as you see here. It is in the `seq_to_string` for `utils.py`. May need to restart kernel to get changes to import\n","\n","2. Add the `data.pkl` file to the directory\n","\n","3. Go to [here](https://github.com/adamklec/copynet.git) for more info"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hv1hmLB8NVY_","executionInfo":{"status":"ok","timestamp":1619988162763,"user_tz":240,"elapsed":5221,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}},"outputId":"74ed8e31-e49f-4dd0-f1c1-e253bfd7aa5c"},"source":["! git clone https://github.com/zachary-m/copynet.git\n","! git clone https://github.com/zachary-m/gc.git\n","! pip install tensorboardX"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'copynet'...\n","remote: Enumerating objects: 36, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 36 (delta 2), reused 0 (delta 0), pack-reused 30\u001b[K\n","Unpacking objects: 100% (36/36), done.\n","Cloning into 'gc'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (2/2), done.\u001b[K\n","remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (3/3), done.\n","Collecting tensorboardX\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n","\u001b[K     |████████████████████████████████| 122kB 17.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (56.0.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPD2OpJjNvAI","executionInfo":{"status":"ok","timestamp":1619988162764,"user_tz":240,"elapsed":5203,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}},"outputId":"bc6f2ab5-5278-4309-ef50-d68e61906fb6"},"source":["import os \n","print(os.getcwd())\n","os.chdir(\"/content/copynet/\")\n","print(os.getcwd())\n","if not os.path.exists(\"/content/copynet/data\"):\n","    os.makedirs(\"/content/copynet/data\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n","/content/copynet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHWsRSLzd-bq","executionInfo":{"status":"ok","timestamp":1619988162765,"user_tz":240,"elapsed":5193,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}},"outputId":"84e1aa56-2685-4acd-b46f-a29d1b961254"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Sun May  2 20:42:42 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2T5tXkYYhGIb","executionInfo":{"status":"ok","timestamp":1619988164952,"user_tz":240,"elapsed":260,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}}},"source":["# torch.cuda.empty_cache()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJNgDCuMNk0B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619988172965,"user_tz":240,"elapsed":7932,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}},"outputId":"bed6c6a8-2971-4470-dbe4-39fb9df3c265"},"source":["import argparse\n","import time\n","import numpy as np\n","import pandas as pd\n","import torch\n","import string\n","from torch import optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader, Dataset\n","import re\n","from dataset import SequencePairDataset\n","from model.encoder_decoder import EncoderDecoder\n","from evaluate import evaluate\n","from utils import to_np, trim_seqs\n","\n","from tensorboardX import SummaryWriter\n","from tqdm.notebook import tqdm\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.is_available():\n","    print(\"Using the GPU!\")\n","else:\n","    print(\"WARNING: Could not find GPU! Using CPU only\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using the GPU!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"qp2zwA2dWlh7","executionInfo":{"status":"ok","timestamp":1619988172966,"user_tz":240,"elapsed":7741,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}},"outputId":"631cd052-07c0-4b9d-ed66-df849b3f013f"},"source":["df = pd.read_pickle(\"/content/gc/train_test_val.pkl\")\n","print(df.data_type.unique())\n","df.head()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["['test' 'train' 'val']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>src</th>\n","      <th>target</th>\n","      <th>data_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ויהיו שם שדי מואב ויבאו יהודה לחם מבית אפרתים ...</td>\n","      <td>שם ונשארו מואב לארץ באו הם שביהודה לחם בית היא...</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>התבן בהיות כאשר ביומו דבר יום מעשיכם כלו לאמר ...</td>\n","      <td>הקש את שקבלתם בזמן יום בכל שעשיתם כמו מעשיכם א...</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ומש וגתר וחול עוץ ארם ובני</td>\n","      <td>ומש וגתר וחול עוץ ארם ובני</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>סביב המזבח על קרנות ונתן השעיר ומדם הפר מדם ול...</td>\n","      <td>מסביב המזבח פנות על וישים התיש ומדם הפר מדם וי...</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>תעוננו ולא תנחשו על הדם תאכלו</td>\n","      <td>עינים תאחזו ואל תכשפו אל הדם עם בעודו בשר תאכל...</td>\n","      <td>test</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 src  ... data_type\n","0  ויהיו שם שדי מואב ויבאו יהודה לחם מבית אפרתים ...  ...      test\n","1  התבן בהיות כאשר ביומו דבר יום מעשיכם כלו לאמר ...  ...      test\n","2                         ומש וגתר וחול עוץ ארם ובני  ...      test\n","3  סביב המזבח על קרנות ונתן השעיר ומדם הפר מדם ול...  ...      test\n","4                      תעוננו ולא תנחשו על הדם תאכלו  ...      test\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Ndz2r9oAaCVt","executionInfo":{"status":"ok","timestamp":1619988172967,"user_tz":240,"elapsed":7531,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}}},"source":["\n","# def remove_notes(word_list):\n","#   return \" \".join([re.sub(r'[\\u0591-\\u05BD\\u05BF-\\u05C2\\u05C4-\\u05C7]', '', token) for token in word_list])\n","\n","# df[\"src\"] = df[\"src\"].apply(lambda row: remove_notes(row))\n","\n","# df[\"target\"] = df[\"target\"].apply(lambda row: remove_notes(row))\n","# results = ['א', 'ב', 'ג', 'ד', 'ה', 'ו', 'ז', 'ח', 'ט', 'י', 'ך',  'כ',  'ל',  'ם',  'מ','ן', 'נ','ס', 'ע', 'ף', 'פ', 'ץ', 'צ', 'ק', 'ר', 'ש', 'ת']\n","# map_letters = dict(list(zip(results, string.ascii_lowercase + \"@\")))\n","# # df = df.replace(map_letters, regex=True)\n","\n","# df[\"reversed_src\"] = df[\"src\"].apply(lambda row: row[::-1])\n","# df[\"reversed_target\"] = df[\"target\"].apply(lambda row: row[::-1])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"AWqPUI2meNFH","executionInfo":{"status":"ok","timestamp":1619988172967,"user_tz":240,"elapsed":7335,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}},"outputId":"ff275ec6-eed8-4b9c-b6d2-6a376306432f"},"source":["df"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>src</th>\n","      <th>target</th>\n","      <th>data_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ויהיו שם שדי מואב ויבאו יהודה לחם מבית אפרתים ...</td>\n","      <td>שם ונשארו מואב לארץ באו הם שביהודה לחם בית היא...</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>התבן בהיות כאשר ביומו דבר יום מעשיכם כלו לאמר ...</td>\n","      <td>הקש את שקבלתם בזמן יום בכל שעשיתם כמו מעשיכם א...</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ומש וגתר וחול עוץ ארם ובני</td>\n","      <td>ומש וגתר וחול עוץ ארם ובני</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>סביב המזבח על קרנות ונתן השעיר ומדם הפר מדם ול...</td>\n","      <td>מסביב המזבח פנות על וישים התיש ומדם הפר מדם וי...</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>תעוננו ולא תנחשו על הדם תאכלו</td>\n","      <td>עינים תאחזו ואל תכשפו אל הדם עם בעודו בשר תאכל...</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9217</th>\n","      <td>ישן תאכלו תבואתה עד בוא התשיעת השנה ישן מן התב...</td>\n","      <td>הישנה מהתבואה תאכלו שנה אותה תבואת הגעת התשיעי...</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>9218</th>\n","      <td>במועדם אתם אשר תקראו קדש מקראי יהוה מועדי אלה</td>\n","      <td>בזמנם אותם שתקבעו קודש מאורעות יהוה חגי אלה</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>9219</th>\n","      <td>האחד לאיל עשרנים שני לפר עשרנים שלשה בשמן בלול...</td>\n","      <td>איל לכל ליטר כ6 5 האיפה עשיריות שלוש בשמן מערב...</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>9220</th>\n","      <td>הישראלי ואיש הישראלית בן במחנה וינצו ישראל בני...</td>\n","      <td>במחנה רבו ישראלי ואיש הישראלית של הבן ישראל בנ...</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>9221</th>\n","      <td>עליו רבה האדם כי רעת ומשפט עת יש לכל חפץ כי</td>\n","      <td>רבה רעה גורמת האדם רעת כי למשפט זמן יש תאוה מל...</td>\n","      <td>train</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9222 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                    src  ... data_type\n","0     ויהיו שם שדי מואב ויבאו יהודה לחם מבית אפרתים ...  ...      test\n","1     התבן בהיות כאשר ביומו דבר יום מעשיכם כלו לאמר ...  ...      test\n","2                            ומש וגתר וחול עוץ ארם ובני  ...      test\n","3     סביב המזבח על קרנות ונתן השעיר ומדם הפר מדם ול...  ...      test\n","4                         תעוננו ולא תנחשו על הדם תאכלו  ...      test\n","...                                                 ...  ...       ...\n","9217  ישן תאכלו תבואתה עד בוא התשיעת השנה ישן מן התב...  ...     train\n","9218      במועדם אתם אשר תקראו קדש מקראי יהוה מועדי אלה  ...     train\n","9219  האחד לאיל עשרנים שני לפר עשרנים שלשה בשמן בלול...  ...     train\n","9220  הישראלי ואיש הישראלית בן במחנה וינצו ישראל בני...  ...     train\n","9221        עליו רבה האדם כי רעת ומשפט עת יש לכל חפץ כי  ...     train\n","\n","[9222 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"wQnMs_sCaJ7G","executionInfo":{"status":"ok","timestamp":1619988185809,"user_tz":240,"elapsed":20001,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}}},"source":["vals = {\"test\":0, \"val\":0, \"train\":0}\n","train_val_test = {\"test\":[], \"val\":[], \"train\":[]}\n","for idx, (i, row) in enumerate(df.iterrows()): # copy path if copy\n","    # print(row[\"data_type\"])\n","    path = \"/content/copynet/data/{}{}.txt\".format(row[\"data_type\"], vals[row[\"data_type\"]])\n","    row[[\"src\",\t\"target\"]].to_csv(path, index=False, header=False)\n","    train_val_test[row[\"data_type\"]].append(path)\n","    vals[row[\"data_type\"]] += 1\n","    "],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"AvOsAEJjaIvk","executionInfo":{"status":"ok","timestamp":1619988185809,"user_tz":240,"elapsed":19809,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}}},"source":["class CustomDataSet(Dataset):\n","  \"\"\"\n","  The Class will act as the container for our dataset. It will take your dataframe, the root path, and also the transform function for transforming the dataset.\n","  \"\"\"\n","  def __init__(self, file_name_list, transform=None):\n","    self.file_name_list = file_name_list\n","    self.transform = transform\n","  \n","  def __len__(self):\n","      # Return the length of the dataset\n","    return len(self.file_name_list)\n","  \n","  def __getitem__(self, idx):\n","      # Return the observation based on an index. Ex. dataset[0] will return the first element from the dataset, in this case the image and the label.\n","    if torch.is_tensor(idx):\n","        idx = int(idx.item())\n","    file_path = self.file_name_list[idx]\n","    input_val, target_val = pd.read_csv(file_path, header=None).T.values.ravel()\n","    return (input_val, target_val)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhrCh-rlNZMU","executionInfo":{"status":"ok","timestamp":1619988186136,"user_tz":240,"elapsed":19978,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}}},"source":["writer = SummaryWriter()\n","\n","def seq_to_string(seq, idx_to_tok, input_tokens=None):\n","    # print(\"DO\", seq, idx_to_tok)\n","    # print(\"HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\", flush=True)\n","    vocab_size = len(idx_to_tok)\n","    seq_length = (seq != 0).sum()\n","    words = []\n","    # print(\"HHELLO\")\n","    for idx in seq[:seq_length]:\n","        \n","        # print(idx, flush=True)\n","        # print(idx.item(), flush=True)\n","        # print(\"HEELLO\", flush=True)\n","        if idx < vocab_size:\n","            \n","            words.append(idx_to_tok[idx.item()]) # CHANGE\n","        elif input_tokens is not None:\n","            words.append(input_tokens[idx - vocab_size])\n","        else:\n","            words.append('<???>')\n","    string = ' '.join(words)\n","    return string\n","def train(encoder_decoder: EncoderDecoder,\n","          train_data_loader: DataLoader,\n","          model_name,\n","          val_data_loader: DataLoader,\n","          keep_prob,\n","          teacher_forcing_schedule,\n","          lr,\n","          max_length):\n","\n","    global_step = 0\n","    loss_function = torch.nn.NLLLoss(ignore_index=0)\n","    optimizer = optim.Adam(encoder_decoder.parameters(), lr=lr)\n","    model_path = './model/' + model_name + '/'\n","\n","    for epoch, teacher_forcing in enumerate(teacher_forcing_schedule):\n","        print('epoch %i' % epoch)\n","\n","        for batch_idx, (input_idxs, target_idxs, input_tokens, target_tokens) in enumerate(tqdm(train_data_loader)):\n","            # input_idxs and target_idxs have dim (batch_size x max_len)\n","            # they are NOT sorted by length\n","            # print(input_tokens, target_tokens)\n","            lengths = (input_idxs != 0).long().sum(dim=1)\n","            sorted_lengths, order = torch.sort(lengths, descending=True)\n","\n","            input_variable = Variable(input_idxs[order, :][:, :max(lengths)])\n","            target_variable = Variable(target_idxs[order, :])\n","            # print(target_variable)\n","\n","            optimizer.zero_grad()\n","            output_log_probs, output_seqs = encoder_decoder(input_variable,\n","                                                            list(sorted_lengths),\n","                                                            targets=target_variable,\n","                                                            keep_prob=keep_prob,\n","                                                            teacher_forcing=teacher_forcing)\n","            # print(output_seqs)\n","            batch_size = input_variable.shape[0]\n","\n","            flattened_outputs = output_log_probs.view(batch_size * max_length, -1)\n","            # print(flattened_outputs)\n","\n","            batch_loss = loss_function(flattened_outputs, target_variable.contiguous().view(-1))\n","            batch_loss.backward()\n","            optimizer.step()\n","\n","            batch_outputs = trim_seqs(output_seqs)\n","            # print(\"target_variable\", target_variable)\n","            batch_targets = [[list(seq[seq > 0])] for seq in list(to_np(target_variable))]\n","            # print(\"batch targets\", batch_targets)\n","            batch_bleu_score = corpus_bleu(batch_targets, batch_outputs, smoothing_function=SmoothingFunction().method1)\n","            # print(\"INPUT STRING\")\n","            # print(\"train loss {}\".format(batch_loss), \"train BLEU {}\".format(batch_bleu_score), )\n","            # WHAT IS THIS?????????\n","            if global_step < 10 or (global_step % 10 == 0 and global_step < 100) or (global_step % 100 == 0 and epoch < 2):\n","                # print(\"INPUT STRING 2\", input_tokens)\n","                input_string = \"Amy, Please schedule a meeting with Marcos on Tuesday April 3rd. Adam Kleczewski\"\n","                \n","                output_string = encoder_decoder.get_response(input_string)\n","                writer.add_text('schedule', output_string, global_step=global_step)\n","\n","                input_string = \"Amy, Please cancel this meeting. Adam Kleczewski\"\n","                output_string = encoder_decoder.get_response(input_string)\n","                writer.add_text('cancel', output_string, global_step=global_step)\n","\n","            if global_step % 100 == 0:\n","\n","                writer.add_scalar('train_batch_loss', batch_loss, global_step)\n","                writer.add_scalar('train_batch_bleu_score', batch_bleu_score, global_step)\n","\n","                for tag, value in encoder_decoder.named_parameters():\n","                    tag = tag.replace('.', '/')\n","                    writer.add_histogram('weights/' + tag, value, global_step, bins='doane')\n","                    writer.add_histogram('grads/' + tag, to_np(value.grad), global_step, bins='doane')\n","\n","            global_step += 1\n","\n","        val_loss, val_bleu_score = evaluate(encoder_decoder, val_data_loader)\n","\n","        writer.add_scalar('val_loss', val_loss, global_step=global_step)\n","        writer.add_scalar('val_bleu_score', val_bleu_score, global_step=global_step)\n","\n","\n","        # for i in val_data_loader:\n","        #   print(i)\n","        encoder_embeddings = encoder_decoder.encoder.embedding.weight.data\n","        encoder_vocab = encoder_decoder.lang.tok_to_idx.keys()\n","        writer.add_embedding(encoder_embeddings, metadata=encoder_vocab, global_step=0, tag='encoder_embeddings')\n","\n","        decoder_embeddings = encoder_decoder.decoder.embedding.weight.data\n","        decoder_vocab = encoder_decoder.lang.tok_to_idx.keys()\n","        writer.add_embedding(decoder_embeddings, metadata=decoder_vocab, global_step=0, tag='decoder_embeddings')\n","\n","    \n","        input_string = \"Amy, Please schedule a meeting with Marcos on Tuesday April 3rd. Adam Kleczewski\"\n","        output_string = encoder_decoder.get_response(input_string)\n","        writer.add_text('schedule', output_string, global_step=global_step)\n","\n","        input_string = \"Amy, Please cancel this meeting. Adam Kleczewski\"\n","        output_string = encoder_decoder.get_response(input_string)\n","        writer.add_text('cancel', output_string, global_step=global_step)\n","\n","        print('val loss: %.5f, val BLEU score: %.5f' % (val_loss, val_bleu_score))\n","        torch.save(encoder_decoder, \"%s%s_%i.pt\" % (model_path, model_name, epoch))\n","\n","        print('-' * 100)\n","\n","\n","def main(model_name, use_cuda, batch_size, teacher_forcing_schedule, keep_prob, val_size, lr, decoder_type, vocab_limit, hidden_size, embedding_size, max_length, seed=42):\n","\n","    model_path = './model/' + model_name + '/'\n","\n","    # TODO: Change logging to reflect loaded parameters\n","\n","    print(\"training %s with use_cuda=%s, batch_size=%i\"% (model_name, use_cuda, batch_size))\n","    print(\"teacher_forcing_schedule=\", teacher_forcing_schedule)\n","    print(\"keep_prob=%f, val_size=%f, lr=%f, decoder_type=%s, vocab_limit=%i, hidden_size=%i, embedding_size=%i, max_length=%i, seed=%i\" % (keep_prob, val_size, lr, decoder_type, vocab_limit, hidden_size, embedding_size, max_length, seed), flush=True)\n","\n","    if os.path.isdir(model_path):\n","\n","        print(\"loading encoder and decoder from model_path\")\n","        encoder_decoder = torch.load(model_path + model_name + '.pt')\n","\n","        print(\"creating training and validation datasets with saved languages\")\n","        train_dataset = SequencePairDataset(lang=encoder_decoder.lang,\n","                                            use_cuda=use_cuda,\n","                                            is_val=False,\n","                                            val_size=val_size,\n","                                            use_extended_vocab=(encoder_decoder.decoder_type=='copy'))\n","        \n","        val_dataset = SequencePairDataset(lang=encoder_decoder.lang,\n","                                          use_cuda=use_cuda,\n","                                          is_val=True,\n","                                          val_size=val_size,\n","                                          use_extended_vocab=(encoder_decoder.decoder_type=='copy'))\n","\n","    else:\n","        os.mkdir(model_path)\n","\n","        print(\"creating training and validation datasets\")\n","        train_dataset = SequencePairDataset(vocab_limit=vocab_limit,\n","                                            use_cuda=use_cuda,\n","                                            is_val=False,\n","                                            val_size=val_size,\n","                                            seed=seed,\n","                                            use_extended_vocab=(decoder_type=='copy'))\n","        print(\"TRAIN SIZE\", len(train_dataset))\n","        val_dataset = SequencePairDataset(lang=train_dataset.lang,\n","                                          use_cuda=use_cuda,\n","                                          is_val=True,\n","                                          val_size=val_size,\n","                                          seed=seed,\n","                                          use_extended_vocab=(decoder_type=='copy'))\n","        print(\"TEST SIZE\", len(val_dataset))\n","        print(\"creating encoder-decoder model\")\n","        encoder_decoder = EncoderDecoder(train_dataset.lang,\n","                                         max_length,\n","                                         embedding_size,\n","                                         hidden_size,\n","                                         decoder_type)\n","\n","        torch.save(encoder_decoder, model_path + '/%s.pt' % model_name)\n","\n","    if use_cuda:\n","        encoder_decoder = encoder_decoder.to(device)\n","    else:\n","        encoder_decoder = encoder_decoder.cpu()\n","\n","    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_data_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    train(encoder_decoder,\n","          train_data_loader,\n","          model_name,\n","          val_data_loader,\n","          keep_prob,\n","          teacher_forcing_schedule,\n","          lr,\n","          encoder_decoder.decoder.max_length)\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"NkGFOB2hvr_R","executionInfo":{"status":"ok","timestamp":1619988186138,"user_tz":240,"elapsed":19797,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}}},"source":["# vocab_limit = []\n","# for i, row in df.iterrows():\n","# https://github.com/omilab/Neural-Sentiment-Analyzer-for-Modern-Hebrew/tree/master/data"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ZDk_KvQePBk"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":719,"referenced_widgets":["fcefa0a9ebb049f5823a4946e0fdf71a","6c613c9956694a4fb527940584ddf838","7557ea80e8d74e2588ab92e1935822c4","98079e483d2046df803a9059aeb5339c","43d5ec8cf69d49d29438aad73fd32f20","29d44bfc70c74dde8c673acb141f6d92","19a9a8222d7b4b81a59a7aa124baae25","dbaabe5e35c9494ab78f205370949d1f"]},"id":"eZTo5CF8bAFi","executionInfo":{"status":"error","timestamp":1619988200456,"user_tz":240,"elapsed":33769,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}},"outputId":"f9be53be-2f1e-46d8-9356-aaa0c7a5ffd5"},"source":["model = main(model_name = \"models\",\n","     use_cuda=True,\n","     batch_size=16,\n","     teacher_forcing_schedule= [.001]*5 + [.0005]*5+ [.0001]*10+ [.00001]*5,  #[.001]*5 + [.0005]*10 + [.001]*15 +\n","     keep_prob=1,\n","     val_size=0.1,\n","     lr=0.0001,\n","     decoder_type='copy',\n","     vocab_limit=5000,\n","     hidden_size=500, # 500 https://arxiv.org/pdf/1603.06393.pdf  # increase\n","     embedding_size=350, #350  increase\n","     max_length=500, # increase\n","     seed=42)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["training models with use_cuda=True, batch_size=16\n","teacher_forcing_schedule= [0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05]\n","keep_prob=1.000000, val_size=0.100000, lr=0.000100, decoder_type=copy, vocab_limit=5000, hidden_size=500, embedding_size=350, max_length=500, seed=42\n","creating training and validation datasets\n","reading file 0/8300\n","reading file 1000/8300\n","reading file 2000/8300\n","reading file 3000/8300\n","reading file 4000/8300\n","reading file 5000/8300\n","reading file 6000/8300\n","reading file 7000/8300\n","reading file 8000/8300\n","TRAIN SIZE 8300\n","TEST SIZE 922\n","creating encoder-decoder model\n","epoch 0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcefa0a9ebb049f5823a4946e0fdf71a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=519.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-720534e40501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m      \u001b[0membedding_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#350  increase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m      \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# increase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m      seed=42)\n\u001b[0m","\u001b[0;32m<ipython-input-11-2d6881f3a98d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model_name, use_cuda, batch_size, teacher_forcing_schedule, keep_prob, val_size, lr, decoder_type, vocab_limit, hidden_size, embedding_size, max_length, seed)\u001b[0m\n\u001b[1;32m    198\u001b[0m           \u001b[0mteacher_forcing_schedule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m           \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m           encoder_decoder.decoder.max_length)\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-2d6881f3a98d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder_decoder, train_data_loader, model_name, val_data_loader, keep_prob, teacher_forcing_schedule, lr, max_length)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# print(flattened_outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m         raise ValueError(\n\u001b[0;32m-> 2385\u001b[0;31m             \u001b[0;34m\"Expected input batch_size ({}) to match target batch_size ({}).\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m         )\n\u001b[1;32m   2387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (8000) to match target batch_size (3200)."]}]},{"cell_type":"code","metadata":{"id":"p5Ef9MwLb3Ua","executionInfo":{"status":"aborted","timestamp":1619988200453,"user_tz":240,"elapsed":33565,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}}},"source":["# /content/copynet/evaluate.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","#   input_variable = Variable(input_idxs[order, :][:, :max(input_lengths)], volatile=True)\n","# /content/copynet/evaluate.py:29: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","#   target_variable = Variable(target_idxs[order, :], volatile=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjdBNPAcOLIv","executionInfo":{"status":"aborted","timestamp":1619988200455,"user_tz":240,"elapsed":33380,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}}},"source":["if __name__ == '__main__':\n","    parser = argparse.ArgumentParser(description='Parse training parameters')\n","    parser.add_argument('./data/', type=str,\n","                        help='the name of a subdirectory of ./model/ that '\n","                             'contains encoder and decoder model files')\n","    \n","    parser.add_argument('--epochs', type=int, default=10,\n","                        help='the number of epochs to train')\n","\n","    parser.add_argument('--use_cuda', action='store_true',\n","                        help='flag indicating that cuda will be used')\n","\n","    parser.add_argument('--batch_size', type=int, default=128,\n","                        help='number of examples in a batch')\n","\n","    parser.add_argument('--teacher_forcing_fraction', type=float, default=0.5,\n","                        help='fraction of batches that will use teacher forcing during training')\n","\n","    parser.add_argument('--scheduled_teacher_forcing', action='store_true',\n","                        help='Linearly decrease the teacher forcing fraction '\n","                             'from 1.0 to 0.0 over the specified number of epocs')\n","\n","    parser.add_argument('--keep_prob', type=float, default=1.0,\n","                        help='Probablity of keeping an element in the dropout step.')\n","\n","    parser.add_argument('--val_size', type=float, default=0.1,\n","                        help='fraction of data to use for validation')\n","\n","    parser.add_argument('--lr', type=float, default=0.001,\n","                        help='Learning rate.')\n","\n","    parser.add_argument('--decoder_type', type=str, default='copy',\n","                        help=\"Allowed values 'copy' or 'attn'\")\n","\n","    parser.add_argument('--vocab_limit', type=int, default=5000,\n","                        help='When creating a new Language object the vocab'\n","                             'will be truncated to the most frequently'\n","                             'occurring words in the training dataset.')\n","\n","    parser.add_argument('--hidden_size', type=int, default=256,\n","                        help='The number of RNN units in the encoder. 2x this '\n","                             'number of RNN units will be used in the decoder')\n","\n","    parser.add_argument('--embedding_size', type=int, default=128,\n","                        help='Embedding size used in both encoder and decoder')\n","\n","    parser.add_argument('--max_length', type=int, default=200,\n","                        help='Sequences will be padded or truncated to this size.')\n","\n","    args = parser.parse_args()\n","\n","    writer = SummaryWriter('./logs/%s_%s' % (args.model_name, str(int(time.time()))))\n","    if args.scheduled_teacher_forcing:\n","        schedule = np.arange(1.0, 0.0, -1.0/args.epochs)\n","    else:\n","        schedule = np.ones(args.epochs) * args.teacher_forcing_fraction\n","\n","    # main(args.model_name, args.use_cuda, args.batch_size, schedule, args.keep_prob, args.val_size, args.lr, args.decoder_type, args.vocab_limit, args.hidden_size, args.embedding_size, args.max_length)\n","    # main(str(int(time.time())), args.use_cuda, args.batch_size, schedule, args.keep_prob, args.val_size, args.lr, args.decoder_type, args.vocab_limit, args.hidden_size, args.embedding_size, args.max_length)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvKFLGseb83u","executionInfo":{"status":"aborted","timestamp":1619988126337,"user_tz":240,"elapsed":36981,"user":{"displayName":"Zachary Metzman","photoUrl":"","userId":"12527305156258230556"}}},"source":[""],"execution_count":null,"outputs":[]}]}